{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intialise log\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#  utilities \n",
    "\n",
    "def random_binomial(shape, p=0.0, dtype=None, seed=None):\n",
    "    \"\"\"Returns a tensor with random binomial distribution of values.\n",
    "    # Arguments\n",
    "        shape: A tuple of integers, the shape of tensor to create.\n",
    "        p: A float, `0. <= p <= 1`, probability of binomial distribution.\n",
    "        dtype: String, dtype of returned tensor.\n",
    "        seed: Integer, random seed.\n",
    "    # Returns\n",
    "        A tensor.\n",
    "    \"\"\"\n",
    "    if dtype is None:\n",
    "        dtype = 'float32'\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(10e6)\n",
    "    return tf.where(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,\n",
    "                    tf.ones(shape, dtype=dtype),\n",
    "                    tf.zeros(shape, dtype=dtype))\n",
    "\n",
    "#reshape Data\n",
    "# sample n frame from videos\n",
    "def my_reshape(data_in ,number_of_frame = 2):\n",
    "    N, M, H, W = data_in.shape\n",
    "    n = N-number_of_frame+1\n",
    "    data_out = np.zeros((n * M, number_of_frame, 64, 64),'uint8')\n",
    "    for j in range(M):\n",
    "        for i in range(n):\n",
    "            data_out[j*n+i] = data_in[i:i+number_of_frame,j]\n",
    "    \n",
    "    return data_out\n",
    "\n",
    "#show filter \n",
    "def dispims(M, height, width, border=0, bordercolor=0.0, layout=None, **kwargs):\n",
    "    from pylab import cm, ceil\n",
    "    numimages = M.shape[1]\n",
    "    if layout is None:\n",
    "        n0 = int(np.ceil(np.sqrt(numimages)))\n",
    "        n1 = int(np.ceil(np.sqrt(numimages)))\n",
    "    else:\n",
    "        n0, n1 = layout\n",
    "    im = bordercolor * np.ones(((height+border)*n0+border,(width+border)*n1+border),dtype='<f8')\n",
    "    for i in range(n0):\n",
    "        for j in range(n1):\n",
    "            if i*n1+j < M.shape[1]:\n",
    "                im[i*(height+border)+border:(i+1)*(height+border)+border,\n",
    "                   j*(width+border)+border :(j+1)*(width+border)+border] = np.vstack((\n",
    "                            np.hstack((np.reshape(M[:,i*n1+j],(height, width)),\n",
    "                                   bordercolor*np.ones((height,border),dtype=float))),\n",
    "                            bordercolor*np.ones((border,width+border),dtype=float)\n",
    "                            ))\n",
    "    pylab.imshow(im, cmap=cm.gray, interpolation='nearest', **kwargs)\n",
    "    pylab.show()\n",
    "    \n",
    "# Manage Data\n",
    "class Dataset:\n",
    "    def __init__(self,data):\n",
    "        self._index_in_epoch = 0\n",
    "        self._epochs_completed = 0\n",
    "        self._data = data\n",
    "        self._num_examples = data.shape[0]\n",
    "        pass\n",
    "\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "\n",
    "    def next_batch(self,batch_size,shuffle = True):\n",
    "        start = self._index_in_epoch\n",
    "        if start == 0 and self._epochs_completed == 0:\n",
    "            idx = np.arange(0, self._num_examples)  # get all possible indexes\n",
    "            np.random.shuffle(idx)  # shuffle indexe\n",
    "            self._data = self.data[idx]  # get list of `num` random samples\n",
    "\n",
    "        # go to the next batch\n",
    "        if start + batch_size > self._num_examples:\n",
    "            self._epochs_completed += 1\n",
    "            rest_num_examples = self._num_examples - start\n",
    "            data_rest_part = self.data[start:self._num_examples]\n",
    "            idx0 = np.arange(0, self._num_examples)  # get all possible indexes\n",
    "            np.random.shuffle(idx0)  # shuffle indexes\n",
    "            self._data = self.data[idx0]  # get list of `num` random samples\n",
    "\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size - rest_num_examples #avoid the case where the #sample != integar times of batch_size\n",
    "            end =  self._index_in_epoch  \n",
    "            data_new_part =  self._data[start:end]  \n",
    "            return np.concatenate((data_rest_part, data_new_part), axis=0)\n",
    "        else:\n",
    "            self._index_in_epoch += batch_size\n",
    "            end = self._index_in_epoch\n",
    "            return self._data[start:end]\n",
    "        \n",
    "if (not os.path.isfile('log.npy')):\n",
    "    print (\"intialise log\")\n",
    "    log = np.array([])\n",
    "else :\n",
    "    print (\"load log\")\n",
    "    log =np.load(\"log.npy\")\n",
    "        \n",
    "numpy_rng = np.random.RandomState(1)\n",
    "SMALL = 0.000001\n",
    "print_every_epoch = 5\n",
    "batch_size = 64\n",
    "training_epochs =300\n",
    "\n",
    "# numfac1  = 1024\n",
    "# nummap1  = 512\n",
    "numfac1  = 512\n",
    "nummap1  = 256\n",
    "# numfac1  = 256\n",
    "# nummap1  = 512\n",
    "\n",
    "# numfac2  = 512\n",
    "# nummap2  = 256\n",
    "numfac2  = 128\n",
    "nummap2  = 64\n",
    "# numfac2  = 64\n",
    "# nummap2  = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Exist\n",
      "(20, 10000, 64, 64)\n",
      "(20, 1, 64, 64)\n",
      "(20, 1, 64, 64)\n",
      "(20, 10000, 64, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHE5JREFUeJztnX+MXcV1x79nn3ftxdjGBntZbIJN4mAsfhjkGvJDqYMh\nJYTgVFVofsqpqKxKaUrUpAFSKRVRozhqFaVtolRWE+IqJBQRUlzyS44LpWkoYMAEbANLiF0MtheM\njQ3YXnv39I93/e7M7N7ZeXfvve+9ne9HWr25d+bNPe++Pe+eM2fmjKgqCCHx0dVqAQghrYHKT0ik\nUPkJiRQqPyGRQuUnJFKo/IRECpWfkEiZkPKLyNUi8oyIPCciNxclFCGkfCTvJB8RqQF4FsBVAHYD\neATAR1V1e3HiEULKYsoE3rsCwHOq+jwAiMgdAFYDyFT+nlqv9k6ZOYFLEkJ8HDlxCEPDRySk7USU\nfz6AF4zj3QAu872hd8pMvPOsj0/gkoQQH79+6fbgthNR/iBEZC2AtQAwrTaj7MsRQgKZyIDfiwDO\nNo4XJOcsVHW9qi5X1eU9td4JXI4QUiQTUf5HACwWkUUi0gPgIwA2FiMWIaRscpv9qnpCRP4cwC8A\n1AB8V1W3FSYZIaRUJuTzq+pPAfy0IFkIIRVS+oAfiZSRwPkjXUFRKVICnN5LSKRQ+QmJFJr9LqHm\naisxTeVOkNdHO8ofiSvCJz8hkULlJyRSqPyERAp9fp/PWfaeBm7/EuhrDrehn+yS5975Pn8R30Xe\n+xv6Ph9tOI7AJz8hkULlJyRS4jH7s8x7nznpqxsZmZg8pLV0NfHcM/8PQl0At10bznjkk5+QSKHy\nExIpk8vsDzWtTDMur2kfOPrMXZBbi2SZ6cPDbsPsTkwXwfd9mn3kjeRUCJ/8hEQKlZ+QSKHyExIp\nne3zN7MiLMvPz+nXB/vyZa9a0whDjuJ5Zjn3Q822njCa1yP3/Y9kjQe4Pn6ecGHJ8MlPSKRQ+QmJ\nlM42+324ZnmomZ7H1PcuDirALO/AcOGJJW8Z83z3Swes40PLzmyU1XkUzXp0T1p3+PW0Qp0wnRfj\n/ptvc1wHhXGPXffAuP+jQodZLoE7g7ANw4B88hMSKVR+QiKFyk9IpExen9+H6aflDeeZfr7Pr8/r\nr494fNCsdjl59ZrzrONXrjnWKH/qwgcb5bt3Xmy165mSOtHXLXjSqtu0L92UVTWVf/WCx6x2a2ft\nbJS7pWbVrdp+XaM89cM5V8Vl3n/PdzaS/Ux0xyWsq4UmI+mUUJ+IfFdEBkXkKePcHBHZJCIDyevs\ncsUkhBRNiNn/PQBXO+duBrBZVRcD2JwcE0I6iHHNflV9QEQWOqdXA1iZlDcAuB/ATQXK1TJymfqh\n78lLAaHEkcV26O3grUca5bsu+Hur7phxuaOamuLXXviE1W5W1/FG+bWRbqvuuPG+23/y+43yPz34\nQavd/I/9a6N82dS9Vt1tb/9Bo/xn+gEE4THZLbzNnHvqm1GY2YXTRzPJQyoir0R9qnoyCLsXQF9B\n8hBCKmLCP0daf1RmPppEZK2IbBGRLUPDR7KaEUIqJu9o/z4R6VfVPSLSD2Awq6GqrgewHgBmTe0r\nd6qaL0lH4Ai//R53lmAOU7+FC2+OX7CoUf6j9ZusunN70q/ssWPzrLrDI72NcrecaJRrzm/85+/7\n40b5rM32SP2sx/Y1ym8b3NYoH12x2BbyY2nx10fPsqpu+dHH0z5GtiGILs/9Ns1397v1RVTM79Bx\nK8zR/+CRfx+hUZ4CyPvk3whgTVJeA+CeYsQhhFRFSKjvhwAeBHCeiOwWkRsArANwlYgMALgyOSaE\ndBAho/0fzahaVbAshJAK6bwZfgUnxxgV2vP566Gr+nx+fsnJPczPc/xLBxvlbrFXwg0Mpavp/ufA\n26y6J35yfqM8Y1f6WWZvtP3uJXg6W46M8zs/YR9vPzK/UR48PsOqO/fudCVfaPIU8Q2x+MYDTF/e\ntYfLnpHXotl/7Rd8JIRUApWfkEjpPLM/L4ZpZZmQzZjsJj73wGPaF57H35Nfbug7qWn/1d/7kFV3\n1n+n75vxhD2z7i0v2zP5Jspr117YKF934RarbvexdFnIr+641Kqbvz1QDmP2nO/+BrsE7ixB69D9\nro1rZ4X9APt78iX6qBA++QmJFCo/IZFC5SckUjrb5y97C+3QMKDj4/tXBhY83ddzrVn/8RujnN1F\nGROQh5el03in/mmaiPOVY6da7XYemtMoz//21rDOQ5NoApnjAZl7+I2FNeV2VKVRrrmVbQ2f/IRE\nCpWfkEjpbLPfJTQfX+gsPl8YcCQjdOjimqQVhvpaycCankb5/Clp0o8d++0VhHO/PDU9CP0szSTG\n8IXYrHamaZ8zmYfZR6098vT54JOfkEih8hMSKZPL7G8XQhOHVGiyFz6zEEDXqdMb5YG/stN/n70w\nnTW469V0Ft9b/sZeYKQDz6blwOtK6K65QOaOzOq0s0b/XXcvxyC+e7+bii5UBJ/8hEQKlZ+QSKHy\nExIpk9fnL2KbLM9qPc3wJce9dqCfX4aPnoeR5Wlij9fPnmbV7bkyTe45p2+/Vbf3QJqY49yvpX6+\nPvN8+MUzElj6V+4F5st32pljAKP8c08CT+vx2X5uvRc++QmJFCo/IZEyucz+0NBZaP79IvDIFLw1\nmA/HNK7N72+Uh2eloThxrrXvHbMa5QOXnLDqZp95yJDxaNqfHrPanWrsvvvmo2dYded+xU7akYsc\n92BUiC1rhl8ZoTctYJGP5U46dQXn8eeTn5BIofITEilUfkIipTN8/rK3uTYJTdLhm8Ib6ucX8Ln2\nf9xOerl/ZeqXT+097jZv0NWV+vXYN92qOzqUbretavrT2XIsuutV61iL3qPQt7LOlzDVdPN9K/x8\nU387N1+Hl5Dtus4WkftEZLuIbBORG5Pzc0Rkk4gMJK+zx+uLENI+hJj9JwB8TlWXArgcwKdFZCmA\nmwFsVtXFADYnx4SQDiFkr749APYk5cMisgPAfACrAaxMmm0AcD+Am0qR0hZo7PKoZjm34c4jh7eZ\nJw/gqMZhpvJrH17eKB/6gzesuq4XTmmUz7ljqFGWo3Y47+XLU0Pt+JV2H8eH0n+L4eNGDrwRO9Q0\nZWo6c2/PFfZWW33biw2him+rLbthodcdxajvKNAPCP1/bNftukRkIYBLADwEoC/5YQCAvQD6CpWM\nEFIqwcovIqcC+BGAz6rqIbNO64+3MX/aRGStiGwRkS1Dw0cmJCwhpDiClF9EulFX/NtV9e7k9D4R\n6U/q+wEMjvVeVV2vqstVdXlPrbcImQkhBTCuzy/1JU7fAbBDVb9uVG0EsAbAuuT1nlIkbIZQvypw\nWu1ofz3D73RXiOXcC1ADxx/2rkx97a4h2+dc/MPDjfKJmWlyzN99tttqB2Pargw7fuve9H3nfyvN\nyLP7urOsZocvTft4bak9pmD5gOZndn1y3ziHmOMNnpV85rTXUSsxjeuZSTVDV/+VgXvtWmvihyFx\n/ncB+CSAJ0Xk5K4KX0Rd6e8UkRsA7AJwfTkiEkLKIGS0/1fIXqm8qlhxCCFV0Rkz/Iogy7xsZiZa\nVjLI0G29EG7a15a8tVHe8ZnTrDoxQmxde+wEG8/+Rcbv9LB9Xt9Mv/ozH7BN3pl3PNQom8b87IG5\nVrtDFxnvm2on5qzNTlcNDr96wLhwM/fb4y5YzYxtuDwr34K362rGLC8iV7/5/2PKVfAqPhfO7Sck\nUqj8hERKPGa/iW8hiC83X9kYZu7vPmwkx+gZspsZJvyJ053FOyNjm4pz/rfHOu574JVGefjp54LE\nO+XXTrs/TF0TawUNgDcvS+um/qyAxB6BLkAZWO5CaKK+Ubn/A9/HZB6EkLKh8hMSKVR+QiIlTp+/\nbApIZLHom083yrvWLrHqjs5N+5+x0/79Pu236RiA6aMPHzxotbMDc2EMHzgwfqOTmC5vVihrvDpS\nKnzyExIpVH5CIoVmf8mEzuhzMWfFLVj3oFVXOy2d8eea81Yfua6M4AVSM7el4cND59shx1cuShcS\nzf9Z831PNoJnF7ZrMg9CyOSByk9IpFD5CYkU+vwl464yU98W4IH4/Pxg8iSUdN4z/3s7GuU3vmiH\nI61ZsKF+rCtT1vvc++ab7lvE/nkF4PXzs+CqPkJIGVD5CYmUyWv25wyxmeZZ2walqpwV53EPzBl/\n531zt/22Q6+n7YqXKhM3tGq5XWZ+RuexZ23l1aKceqNw/4e5qo8QUgRUfkIiZfKa/a6JNJxR57NJ\n3XTOwxmNfclBSt4OLHiEvGRO7Hohu9InUwfM+POO1GeZ4iWP1BcBn/yERAqVn5BIofITEint6fOH\n+sllJ9j09B+8BXgZ5PHr29W39swgzNVdXl+7yu26fJj3oFauTOP2LiLTRORhEXlCRLaJyK3J+Tki\nsklEBpLX2eP1RQhpH0J+Wo4BuEJVLwawDMDVInI5gJsBbFbVxQA2J8eEkA5hXOXXOiena3Unfwpg\nNYANyfkNAD5UioQ+urrsv05HNf1rx/6aQST989FKGU1GRtI/B1Vt/I1+n6Z/HUaQxohILdmhdxDA\nJlV9CECfqu5JmuyFsyszIaS9CVJ+VR1W1WUAFgBYISIXOPWKjKnwIrJWRLaIyJah4SMTFpgQUgxN\n2cqqehDAfQCuBrBPRPoBIHkdzHjPelVdrqrLe2q9E5WXEFIQ44b6RGQugOOqelBEegFcBeBrADYC\nWANgXfJ6T5mCjknVe+kZ2Kv/sv09bzKP0Z2OeXrK/LOs4x1/e2Z68Lr9Fc57MO1j6mvp/en9xVar\n3dErL26UBy/ttupm7kzfd2hR+nxY+M1tVrvhg6+NKa+XZnz7Klcv5h0zKnoab4XTs0Pi/P0ANohI\nDXVL4U5VvVdEHgRwp4jcAGAXgOtLlJMQUjDjKr+q/gbAJWOc3w9gVRlCEULKpz1n+LmmVAeGUYrk\npevOcc4cS4unnrBq9q0yZ8wZFR+6yOnDrLS3AD/yVoyJzHHmcfnM/laH7sYhV069ScYkCI4TQvJA\n5SckUtrT7A8lNNlGC8mdzMPXp69LzSiPameYveI0HBm73Uvvt6MO876103OB9sadrRejE8AnPyGR\nQuUnJFKo/IRESmf7/JEw5Yjjkx8z8sp32XVdb+TIOe+6/KcYTn9XC0N2OcJx3rz9Pjx5+0sPC7Yo\n7MgnPyGRQuUnJFLiNPs7bMbgnNsetI7PeHxpo3zi1B6rrutXj0z4ertufWejfKz/eFpR9m3La/6a\nO/H6duz10Y7JYLhdFyGkDKj8hEQKlZ+QSInT5w/dq69NGdm6vVEu4te7a9o061hrLRoTaZN9BwvB\n9ddrOfYrLPnz88lPSKRQ+QmJlDjN/k6j5C2uR5a93ToemmckCDEu3f1GCe5AEdt15Q3vRQ7vGiGR\nQuUnJFI6w+y3RucDU19XmUNuVM7B9DdVuuz04mUk98hD1/TpjfIbfdOcSnPGXFo8fetBq1muxOmu\nC5Pne/KY+aMW8phtjTrvYp2qZ/uZspjlotOCO/DJT0ikUPkJiRQqPyGR0hk+P7Homjo1PXjbQqvu\nlRVpbv0jc7N9xhOnpOVjC4Yy25k+//9dY+ftX/jqgrS/3S9m9+GjXWbxhcoRGlYswl9vl1V9yTbd\nj4vIvcnxHBHZJCIDyevs8foghLQPzZj9NwLYYRzfDGCzqi4GsDk5JoR0CEFmv4gsAPABAF8B8JfJ\n6dUAViblDQDuB3BTseIlhIbH2nyLqFG4JqSGBc+6zpzXKO/4/HSnNjXhdTjUlHWP0/toWsNHlhy1\nmr30wbc0yvO+ndPsD6WZ8F4eKg0Nt8dQW6gU3wDwBdih3T5V3ZOU9wLoK1IwQki5jKv8InItgEFV\nfTSrjda3Pxnzp1NE1orIFhHZMjR8JL+khJBCCTH73wXgOhG5BsA0ADNF5PsA9olIv6ruEZF+AINj\nvVlV1wNYDwCzpvZ1mF1OyORlXOVX1VsA3AIAIrISwOdV9RMi8ncA1gBYl7zeU6KcraHqvQCz/Frf\nWICbV988DHTqvFEus/9D3VZV/3/tb5Q7MCdK8RS9urCNp/euA3CViAwAuDI5JoR0CE1N8lHV+1Ef\n1Yeq7gewqniRCCFVMLlm+LVqVZ8PxxQ0V/kFr/BzzcljaThv2jP2ijxzt+0eYxHemQ+8avdhdDnw\nSXt+lvanIb2Rw6mpv+SfX7PaDe94LlvGLFwXJvB93nCer4+slXyuS+dd5VeA+d0uMxkN2iPgSAip\nHCo/IZEyucx+H6ZpqMNjnwfgHbfOMBtlxEnYYXbpMe1dUzbUDTix7+VG+eyvvuxpaYjhqesaXmHL\nYYzw9+5M/0VGtg8EXctLJPn2St/ZtwDi+CYIIaOg8hMSKVR+QiIlHp8/lNBkoXmxxh5GnKoK/cSL\nz2sUhxfYq/W6p6TjHr2Dxgq/KuXz4Y4beOTKDO+5Prk5htOMv94Bvn0WfPITEilUfkIipfPM/kK2\ndzJNQafOjAI6Jp2aZqMZ3nNmi5mhP3X7N8N5VYa9HBfj4JIZjfK03sNWXa2Wtp37cDozcKQZebMW\nIxXxmUPN/DLwuT553aIWuQ588hMSKVR+QiKFyk9IpHSGz2/6UmXvdWf5pBNPUTF63GDCXea7B46v\n/cqlaXlWz3Grrtvw+VWMf5FmfNqRjA/q68P3uUL32Rv1vozwnjtO49sjzzdOkWcMo03Cg3zyExIp\nVH5CIqUzzP4cjDK3x04u7Mcx/8SIXmWG/QBvXnZ3BWAW6gtjFjDTbmRq2v/MacesuinmFt01O29f\nMHlkzBvC8+XB9yXwyINHjrba9juA9pOIEFIJVH5CIqWzzf6mRn3NiIGVbcNph4x2QObov2vS+Uz7\nQPMv1D0IpeusM63jnnlvNsrTu+1deqcY/s0xyTnKXjShZnOgjN7P0sTCocy6NhnR98EnPyGRQuUn\nJFKo/IRESmf7/C6+8FsRefzNWWZm2M/t2yeHzxc0+yk4NHR00enW8aXzn08vJbb8T92xtFHu/+2T\npcnUFHl96NAkHV2+GX7GcdkrMStMmBKk/CKyE8Bh1Ee8TqjqchGZA+DfACwEsBPA9ap6oBwxCSFF\n08zP2HtVdZmqLk+ObwawWVUXA9icHBNCOoSJmP2rAaxMyhtQ38PvpgnKUxqmyafecJ6ZpMOpMiN9\nGS6AizZjKhcc3jPpefhZ63jrTy9slGv2BD8suM0w9U2ZOiHU55Bp6jezeCf8Ykb/nu3AfPfRXNzU\nJrv0KoBfisijIrI2OdenqnuS8l4AfYVLRwgpjdAn/7tV9UURmQdgk4g8bVaqqorImCNqyY/FWgCY\nVpsxVhNCSAsIevKr6ovJ6yCAHwNYAWCfiPQDQPI6mPHe9aq6XFWX99R6i5GaEDJhxn3yi8h0AF2q\nejgpvw/AlwFsBLAGwLrk9Z4yBW0LsvzCLsdXN/y2pqbE1mqNondVXwGc849Pjt8IgFQoUyjNJfPI\nmn7rmcLr9m+2dVd6dsA03ixCzP4+AD9OPuQUAD9Q1Z+LyCMA7hSRGwDsAnB9eWISQopmXOVX1ecB\nXDzG+f0AVpUhFCGkfCbXDD8Tz0o701AbnVc/dMWfJ/++6wbkwBc+rJTAkGal5M6Pn22+e2fxVblN\nWYXX4tx+QiKFyk9IpFD5CYmUzvb5Q1fIlXG9LP8fCJ8qmrWfHVCtnxmKEfYbhe+zlE3o/Q4N5/ku\nNep9BSQIbdF3zSc/IZFC5SckUjrb7C8A73ZaWVtO1SvTYt6fUG//FeKanQVsB1YpoWZzaFKOImbx\n+dyDNqFN/vsIIVVD5SckUuIx+7Py6jlRgcykH4BnVl8TI91aXbIGL958dtWJkYtmTOjMxVg5t91y\n67J2Ae4A2v1rJoSUBJWfkEih8hMSKZPX53f9r6yc+J6kma4HN2oMoNFHM7+hLZoJ11QorkQZXTlC\nZwbmDSVm+PZN+fVWf8XuGdhK+OQnJFKo/IRESueZ/dZW2+6CGqPOXdiTVdfE9tpWGDB3yM5YHJNn\nJl3T18tDATKGkmdRjq+7UHM7r2mf112w+m8Pl4BPfkIihcpPSKRQ+QmJlM7z+UPxhfp8YwOhYUBf\nH6HU2sP389IJMpoUsJV3U312mJ9vwic/IZFC5SckUjrb7G8mCUWWmV7EbC4fJW67PSZFyJxF1Z8l\nizI+YxEhQpM2NPNdgu6iiJwmIneJyNMiskNE3iEic0Rkk4gMJK+zyxaWEFIcoT+h/wDg56q6BPWt\nu3YAuBnAZlVdDGBzckwI6RBCdumdBeA9AD4FAKo6BGBIRFYDWJk02wDgfgA3lSFkMD5TayTQ1Dcp\nIjW4L911p+F+ltB70C6LXMqQowPM+yxCnvyLALwM4DYReVxE/iXZqrtPVfckbfaivpsvIaRDCFH+\nKQAuBfBtVb0EwBtwTHytT3Qf8zEgImtFZIuIbBkaPjJReQkhBRGi/LsB7FbVh5Lju1D/MdgnIv0A\nkLwOjvVmVV2vqstVdXlPrbcImQkhBTCuz6+qe0XkBRE5T1WfAbAKwPbkbw2AdcnrPaVKOlGK8M3y\njBu0C0Xk5nfptHtg0sG+elGExvk/A+B2EekB8DyAP0HdarhTRG4AsAvA9eWISAgpgyDlV9WtAJaP\nUbWqWHEIIVXR2TP8qibLVHRN6E4wKYt2g8q4blb/nXB/OwDO7SckUqj8hEQKlZ+QSKHPXwSx+qBl\nf+5Y72tF8MlPSKRQ+QmJFNG8+efyXEzkZdQnBJ0B4JXKLpwN5bChHDbtIEezMpyjqnNDGlaq/I2L\nimxR1bEmDVEOykE5KpKBZj8hkULlJyRSWqX861t0XRfKYUM5bNpBjtJkaInPTwhpPTT7CYmUSpVf\nRK4WkWdE5DkRqSzbr4h8V0QGReQp41zlqcdF5GwRuU9EtovINhG5sRWyiMg0EXlYRJ5I5Li1FXIY\n8tSS/JD3tkoOEdkpIk+KyFYR2dJCOSpLk1+Z8otIDcC3ALwfwFIAHxWRpRVd/nsArnbOtSL1+AkA\nn1PVpQAuB/Dp5B5ULcsxAFeo6sUAlgG4WkQub4EcJ7kR9XTwJ2mVHO9V1WVGaK0VclSXJl9VK/kD\n8A4AvzCObwFwS4XXXwjgKeP4GQD9SbkfwDNVyWLIcA+Aq1opC4BTADwG4LJWyAFgQfIPfQWAe1v1\n3QDYCeAM51ylcgCYBeB3SMbiypajSrN/PoAXjOPdyblW0dLU4yKyEMAlAB5qhSyJqb0V9cSrm7Se\noLUV9+QbAL4AwNwLrBVyKIBfisijIrK2RXJUmiafA37wpx4vAxE5FcCPAHxWVQ+1QhZVHVbVZag/\neVeIyAVVyyEi1wIYVNVHPXJW9d28O7kf70fdHXtPC+SYUJr8ZqlS+V8EcLZxvCA51yqCUo8XjYh0\no674t6vq3a2UBQBU9SCA+1AfE6lajncBuE5EdgK4A8AVIvL9FsgBVX0xeR0E8GMAK1ogx4TS5DdL\nlcr/CIDFIrIoyQL8EQAbK7y+y0bUU44DFaUeFxEB8B0AO1T1662SRUTmishpSbkX9XGHp6uWQ1Vv\nUdUFqroQ9f+H/1TVT1Qth4hMF5EZJ8sA3gfgqarlUNW9AF4QkfOSUyfT5JcjR9kDKc7AxTUAngXw\nWwB/XeF1fwhgD4DjqP+63gDgdNQHmgYA/BLAnArkeDfqJttvAGxN/q6pWhYAFwF4PJHjKQBfSs5X\nfk8MmVYiHfCr+n6cC+CJ5G/byf/NFv2PLAOwJflu/h3A7LLk4Aw/QiKFA36ERAqVn5BIofITEilU\nfkIihcpPSKRQ+QmJFCo/IZFC5SckUv4f0eHHr+zMtIgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116ca9278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      "data_train  (20, 7000, 64, 64) data_test  (20, 3000, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "file_name = 'mnist_test_seq.npy'\n",
    "if not os.path.isfile(file_name):\n",
    "    print(\"could not find moving mnist: download it..\")\n",
    "    url = 'http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy'\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(\"download complete\")\n",
    "else :\n",
    "    print (\"Data Exist\")\n",
    "    \n",
    "data = np.load(file_name)\n",
    "print (data.shape)\n",
    "\n",
    "num_data = data.shape[1]\n",
    "\n",
    "idx =  np.arange(0, num_data)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "num_train = int( 0.7 * num_data)\n",
    "print (num_train)\n",
    "train_idx = idx[0:num_train]\n",
    "test_idx = idx [num_train:num_data]\n",
    "\n",
    "data_train = data[:,train_idx,:,:]\n",
    "data_test = data[:,test_idx,:,:]\n",
    "\n",
    "\n",
    "print (\"data_train \" ,data_train.shape ,\"data_test \" ,data_test.shape   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('mean_all.npy'):\n",
    "    # Get mean and variance of all frames \n",
    "    print ('calculate total mean and var')\n",
    "    data_1 = (my_reshape(data, 1)).astype('float32')\n",
    "    print (\"data1 shape\" , data_1.shape)\n",
    "    v,n,h,w = data_1.shape\n",
    "    data_1 = data_1.reshape((v,h * w))\n",
    "    print (\"data1 shape\" , data_1.shape)\n",
    "    mean_all = data_1.mean(0)[None,:]\n",
    "    data_1 -= mean_all\n",
    "\n",
    "    var_all = data_1.std(0)[None,:]  + data_1.std() * 0.1\n",
    "\n",
    "    np.save(\"mean_all\", mean_all)\n",
    "    np.save(\"var_all\", var_all)\n",
    "else :\n",
    "    print ('load mean and var')\n",
    "    mean_all = np.load('mean_all.npy')\n",
    "    var_all = np.load('var_all.npy')\n",
    "\n",
    "print (mean_all.shape)\n",
    "x_dim = mean_all.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize weights randomly\n"
     ]
    }
   ],
   "source": [
    "# Model of  second order relational auto encoder\n",
    "input_x1 = tf.placeholder(tf.float32, [None, x_dim])\n",
    "input_x2 = tf.placeholder(tf.float32, [None, x_dim])\n",
    "input_x3 = tf.placeholder(tf.float32, [None, x_dim])\n",
    "input_x4 = tf.placeholder(tf.float32, [None, x_dim])\n",
    "\n",
    "mean = tf.constant(mean_all)\n",
    "var = tf.constant(var_all)\n",
    "\n",
    "input_x1_scaled = (input_x1 - mean ) / var\n",
    "input_x2_scaled = (input_x2 - mean ) / var\n",
    "input_x3_scaled = (input_x3 - mean ) / var\n",
    "input_x4_scaled = (input_x4 - mean ) / var\n",
    "\n",
    "\n",
    "# weights for first layer URR1\n",
    "if (not os.path.isfile('U1.npy')) and (not os.path.isfile('UR1.npy')) and (not os.path.isfile('URR1.npy')):\n",
    "    print (\"initialize weights randomly\")\n",
    "    U1 = tf.Variable(tf.random_normal(shape=(x_dim, numfac1)) * 0.01)\n",
    "    V1 = tf.Variable(tf.random_normal(shape=(x_dim, numfac1)) * 0.01)\n",
    "    W1 = tf.Variable(numpy_rng.uniform(low=-0.01, high=+0.01, size=( numfac1, nummap1)).astype('float32'))\n",
    "\n",
    "    bias_U1 = tf.Variable(np.zeros(numfac1, dtype='float32'))\n",
    "    bias_V1 = tf.Variable(np.zeros(numfac1, dtype='float32'))\n",
    "    bias_W1 = tf.Variable(np.zeros(nummap1, dtype='float32'))\n",
    "    \n",
    "    #weights for second layer \n",
    "    U2 = tf.Variable(tf.random_normal(shape=(nummap1, numfac2)) * 0.01)\n",
    "    V2 = tf.Variable(tf.random_normal(shape=(nummap1, numfac2)) * 0.01)\n",
    "    W2 = tf.Variable(numpy_rng.uniform(low=-0.01, high=+0.01, size=( numfac2, nummap2)).astype('float32'))\n",
    "    \n",
    "    bias_U2 = tf.Variable(np.zeros(numfac2, dtype='float32'))\n",
    "    bias_V2 = tf.Variable(np.zeros(numfac2, dtype='float32'))\n",
    "    bias_W2 = tf.Variable(np.zeros(nummap2, dtype='float32'))\n",
    "    \n",
    "else :\n",
    "    print (\"Load weights\")\n",
    "    U1 = tf.Variable(np.load(\"URR1.npy\"))\n",
    "    V1 = tf.Variable(np.load(\"VRR1.npy\"))\n",
    "    W1 = tf.Variable(np.load(\"WRR1.npy\"))\n",
    "    bias_U1 = tf.Variable(np.load(\"bias_URR1.npy\"))\n",
    "    bias_V1 = tf.Variable(np.load(\"bias_VRR1.npy\"))\n",
    "    bias_W1 = tf.Variable(np.load(\"bias_WRR1.npy\"))\n",
    "\n",
    "    #weights for second layer \n",
    "    U2 = tf.Variable(np.load(\"URR2.npy\"))\n",
    "    V2 = tf.Variable(np.load(\"VRR2.npy\"))\n",
    "    W2 = tf.Variable(np.load(\"WRR2.npy\"))\n",
    "    bias_U2 = tf.Variable(np.load(\"bias_URR2.npy\"))\n",
    "    bias_V2 = tf.Variable(np.load(\"bias_VRR2.npy\"))\n",
    "    bias_W2 = tf.Variable(np.load(\"bias_WRR2.npy\"))\n",
    "\n",
    "\n",
    "M1_1 =  tf.sigmoid(tf.matmul(tf.multiply(tf.matmul(input_x1_scaled,U1) +bias_U1 ,tf.matmul(input_x2_scaled,V1)+bias_V1 ), W1)+ bias_W1)\n",
    "M1_2 =  tf.sigmoid(tf.matmul(tf.multiply(tf.matmul(input_x2_scaled,U1) +bias_U1 ,tf.matmul(input_x3_scaled,V1)+bias_V1 ), W1)+ bias_W1)\n",
    "\n",
    "M2 =  tf.sigmoid(tf.matmul(tf.multiply(tf.matmul(M1_1,U2)+bias_U2 ,tf.matmul(M1_2,V2) +bias_V2 ), W2)+ bias_W2)\n",
    "\n",
    "output_M1_3 = tf.matmul(tf.multiply(tf.matmul(M2,tf.transpose(W2)) ,tf.matmul(M1_2,U2) ),tf.transpose(V2))\n",
    "output_x4 = tf.matmul(tf.multiply(tf.matmul(output_M1_3,tf.transpose(W1)) ,tf.matmul(input_x3_scaled,U1) ),tf.transpose(V1))\n",
    "\n",
    "cost_RR = tf.nn.l2_loss(output_x4-input_x4_scaled)\n",
    "\n",
    "optimizer_RR = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost_RR)\n",
    "\n",
    "U1_normalized = tf.nn.l2_normalize(U1, [0,1], epsilon=1e-12, name=None)\n",
    "V1_normalized = tf.nn.l2_normalize(V1, [0,1], epsilon=1e-12, name=None)\n",
    "U2_normalized = tf.nn.l2_normalize(U2, [0,1], epsilon=1e-12, name=None)\n",
    "V2_normalized = tf.nn.l2_normalize(V2, [0,1], epsilon=1e-12, name=None)\n",
    "\n",
    "normalize_U1 = U1.assign(U1_normalized)\n",
    "normalize_V1 = V1.assign(V1_normalized)\n",
    "normalize_U2 = U2.assign(U2_normalized)\n",
    "normalize_V2 = V2.assign(V2_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2  (119000, 4, 4096)\n",
      "data_test_reshaped  (51000, 4, 4096)\n"
     ]
    }
   ],
   "source": [
    "#data for second order relational auto encoder\n",
    "data_2 = my_reshape(data_train, 4) # get 4 frame in each row\n",
    " \n",
    "v,n,h,w = data_2.shape\n",
    "data_2 = data_2.reshape((v,n,h * w))\n",
    "print (\"data_2 \" ,data_2.shape)\n",
    "\n",
    "ntrain = data_2.shape[0]\n",
    "dataset2 = Dataset(data_2)\n",
    "data_2=0\n",
    "\n",
    "#For Test \n",
    "data_test_reshaped = my_reshape(data_test, 4) # get 4 frame in each row\n",
    " \n",
    "v,n,h,w = data_test_reshaped.shape\n",
    "data_test_reshaped = data_test_reshaped.reshape((v,n,h * w))\n",
    "print (\"data_test_reshaped \" ,data_test_reshaped.shape)\n",
    "\n",
    "ntest = data_test_reshaped.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/300 cost: 651.885823841  test_cost: 625.534117647\n",
      "Epoch: 001/300 cost: 616.332395056  test_cost: 621.920980392\n"
     ]
    }
   ],
   "source": [
    "#batch_size = 1000\n",
    "num_batches = int(ntrain/batch_size)\n",
    "#training_epochs = 300 \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    import pylab\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    pylab.figure(figsize=(20, 20)) \n",
    "    pylab.subplot(1, 2, 1)\n",
    "    dispims(U1.eval(sess), 64, 64, 2)\n",
    "    pylab.figure(figsize=(20, 20)) \n",
    "    pylab.subplot(1, 2, 2)\n",
    "    dispims(V1.eval(sess), 64, 64, 2)\n",
    "\n",
    "    pylab.figure(figsize=(20, 20)) \n",
    "    pylab.subplot(1, 2, 1)\n",
    "    dispims(U2.eval(sess), int(np.sqrt(nummap1)), int(np.sqrt(nummap1)), 2)\n",
    "    pylab.figure(figsize=(20, 20)) \n",
    "    pylab.subplot(1, 2, 2)\n",
    "    dispims(V2.eval(sess), int(np.sqrt(nummap1)), int(np.sqrt(nummap1)), 2)\n",
    "    \n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        total_cost = 0\n",
    "        for batch_id in range(num_batches):\n",
    "            batch = (dataset2.next_batch(batch_size)).astype('float32')\n",
    "            batch_x1s = batch[:,0,:]\n",
    "            batch_x2s = batch[:,1,:]\n",
    "            batch_x3s = batch[:,2,:]\n",
    "            batch_x4s = batch[:,3,:]\n",
    "     \n",
    "            sess.run(optimizer_RR, feed_dict={input_x1: batch_x1s, input_x2: batch_x2s, input_x3: batch_x3s, input_x4: batch_x4s})\n",
    "#             sess.run(normalize_U1)\n",
    "#             sess.run(normalize_V1)\n",
    "#             sess.run(normalize_U2)\n",
    "#             sess.run(normalize_V2)\n",
    "            cost_ = sess.run(cost_RR, feed_dict={input_x1: batch_x1s, input_x2: batch_x2s, input_x3: batch_x3s, input_x4: batch_x4s}) \n",
    "            total_cost += cost_\n",
    "            #print (\"I: %03d/%03d E: %03d i:%03d/%03d cost: %.9f\" % (epoch*num_batches+batch_id,training_epochs*num_batches ,epoch,batch_id,num_batches,cost_/batch_size) ) \n",
    "        \n",
    "        \n",
    "        test_set_cost_= sess.run(cost_RR, feed_dict={input_x1: data_test_reshaped[:,0,:], input_x2: data_test_reshaped[:,1,:], input_x3: data_test_reshaped[:,2,:], input_x4: data_test_reshaped[:,3,:]})\n",
    "        log = np.append(log,test_set_cost_/ntest )\n",
    "        \n",
    "        print (\"Epoch: %03d/%03d cost: %.9f  test_cost: %.9f\" % (epoch,training_epochs ,total_cost / ntrain ,test_set_cost_/ntest ) )\n",
    "        np.save(\"URR1\", np.array(U1.eval(sess)))\n",
    "        np.save(\"VRR1\", np.array(V1.eval(sess)))\n",
    "        np.save(\"WRR1\", np.array(W1.eval(sess)))\n",
    "        np.save(\"bias_VRR1\", np.array(bias_V1.eval(sess)))\n",
    "        np.save(\"bias_URR1\", np.array(bias_U1.eval(sess)))\n",
    "        np.save(\"bias_WRR1\", np.array(bias_W1.eval(sess)))\n",
    "        np.save(\"URR2\", np.array(U2.eval(sess)))\n",
    "        np.save(\"VRR2\", np.array(V2.eval(sess)))\n",
    "        np.save(\"WRR2\", np.array(W2.eval(sess)))\n",
    "        np.save(\"bias_URR2\", np.array(bias_U2.eval(sess)))\n",
    "        np.save(\"bias_VRR2\", np.array(bias_V2.eval(sess)))\n",
    "        np.save(\"bias_WRR2\", np.array(bias_W2.eval(sess)))\n",
    "        np.save(\"log\", log)\n",
    "        if ((epoch+1) % print_every_epoch) == 0 :\n",
    "            pylab.figure(figsize=(20, 20)) \n",
    "            pylab.subplot(1, 2, 1)\n",
    "            dispims(U1.eval(sess), 64, 64, 2)\n",
    "            pylab.figure(figsize=(20, 20)) \n",
    "            pylab.subplot(1, 2, 2)\n",
    "            dispims(V1.eval(sess), 64, 64, 2)\n",
    "\n",
    "            pylab.figure(figsize=(20, 20)) \n",
    "            pylab.subplot(1, 2, 1)\n",
    "            dispims(U2.eval(sess),int(np.sqrt(nummap1)), int(np.sqrt(nummap1)), 2)\n",
    "            pylab.figure(figsize=(20, 20)) \n",
    "            pylab.subplot(1, 2, 2)\n",
    "            dispims(V2.eval(sess), int(np.sqrt(nummap1)), int(np.sqrt(nummap1)), 2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
