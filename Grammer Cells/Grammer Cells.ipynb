{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Utile\n",
    "def random_binomial(shape, p=0.0, dtype=None, seed=None):\n",
    "    \"\"\"Returns a tensor with random binomial distribution of values.\n",
    "    # Arguments\n",
    "        shape: A tuple of integers, the shape of tensor to create.\n",
    "        p: A float, `0. <= p <= 1`, probability of binomial distribution.\n",
    "        dtype: String, dtype of returned tensor.\n",
    "        seed: Integer, random seed.\n",
    "    # Returns\n",
    "        A tensor.\n",
    "    \"\"\"\n",
    "    if dtype is None:\n",
    "        dtype = 'float32'\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(10e6)\n",
    "    return tf.where(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,\n",
    "                    tf.ones(shape, dtype=dtype),\n",
    "                    tf.zeros(shape, dtype=dtype))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Exist\n",
      "(20, 10000, 64, 64)\n",
      "4096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LOAD DATA\n",
    "file_name = 'mnist_test_seq.npy'\n",
    "if not os.path.isfile(file_name):\n",
    "    print(\"could not find moving mnist: download it..\")\n",
    "    url = 'http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy'\n",
    "    urllib.urlretrieve(url, file_name)\n",
    "    print(\"download complete\")\n",
    "else :\n",
    "    print (\"Data Exist\")\n",
    "    \n",
    "data = np.load(file_name)\n",
    "print data.shape\n",
    "\n",
    "x_dim = data.shape[2] * data.shape[3]\n",
    "print x_dim\n",
    "\n",
    "#Preprocess Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reshape Data\n",
    "\n",
    "def reshape(data_in ,number_of_frame = 2):\n",
    "    N, M, H, W = batch.shape\n",
    "    n = M-number_of_frame+1\n",
    "    data_out = np.zeros((n * N, number_of_frame, 64, 64), 'uint8')\n",
    "    for j in range(N):\n",
    "        for i in range(n):\n",
    "            data_out[j*] = batch[j, i:i+n]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_rng = np.random.RandomState(1)\n",
    "\n",
    "numfac  = 512\n",
    "nummap  = 256\n",
    "\n",
    "# pretrainig first layer\n",
    "input_x1 = tf.placeholder(tf.float32, [None, x_dim])\n",
    "input_x2 = tf.placeholder(tf.float32, [None, x_dim])\n",
    "\n",
    "U1 = tf.Variable(tf.random_normal(shape=(x_dim, numfac)) * 0.01)\n",
    "V1 = tf.Variable(tf.random_normal(shape=(x_dim, numfac)) * 0.01)\n",
    "W1 = tf.Variable(numpy_rng.uniform(low=-0.01, high=+0.01, size=( numfac, nummap)).astype('float32'))\n",
    "\n",
    "bias_U1 = tf.Variable(np.zeros(numfac, dtype='float32'))\n",
    "bias_V1 = tf.Variable(np.zeros(numfac, dtype='float32'))\n",
    "bias_W1 = tf.Variable(np.zeros(nummap, dtype='float32'))\n",
    "bias_U1_out = tf.Variable(np.zeros(x_dim, dtype='float32'))\n",
    "bias_V1_out = tf.Variable(np.zeros(x_dim, dtype='float32'))\n",
    "bias_W1_out = tf.Variable(np.zeros(numfac, dtype='float32'))\n",
    "\n",
    "# m=sig(W(U*X1 . V*X2 ))\n",
    "M1 =  tf.sigmoid(tf.matmul(tf.multiply(tf.matmul(input_x1,U1) + bias_U1,tf.matmul(input_x2,V1) + bias_V1), W1)+ bias_W1)\n",
    "\n",
    "output_x1 = tf.matmul(tf.multiply(tf.matmul(M1,tf.transpose(W1)) + bias_W1_out,tf.matmul(input_x2,V1) + bias_V1),tf.transpose(U1))+ bias_U1_out\n",
    "output_x2 = tf.matmul(tf.multiply(tf.matmul(M1,tf.transpose(W1)) + bias_W1_out,tf.matmul(input_x1,U1) + bias_U1), tf.transpose(V1))+ bias_V1_out\n",
    "\n",
    "cost_1 = tf.nn.l2_loss(output_x1-input_x1) + tf.nn.l2_loss(output_x2-input_x2)\n",
    "optimizer_1 = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
